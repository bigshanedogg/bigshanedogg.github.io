---
layout: post
date: 2016-03-11 23:56
title:  "Sample Data"
mood: happy
category: 
- docs
---

요즘 조금씩이라도 눈팅하게 되는 커뮤니티 중 하나가 케라스 코리아 오픈채팅방이다. 단 몇 번이라도 오프라인 네트워킹에 참여해봤기 때문이고, 가장 많이 쓰는 프레임워크이기 때문인 듯하다.
채팅방에 종종 '~한 문제를 해결하려고 하는데, 어떤 모델부터 찾아봐야할까요?'라는 메세지가 종종 뜬다.
이런 메세지는 좋은 복습의 기회이자 토론의 시작이 될 수 있기 때문에, '나라면 어떻게 접근할까'하고 같이 고민해본다.

물론 대부분의 경우, 데이터를 보지 못한 상황에서 모델을 선택하는 일을 쉽지 않다. 
종종 질문이 구체적일 때나 구현 관련된 메세지의 경우는 비교적 깔끔한 결론이 나오지만, 대부분의 막연한 질문에 대해선 책 1~2권 읽으면 누구나 해줄 수 있는 피상적인 결론만 나올 뿐이다.
<!--more-->
LSTM을 사용한다거나, Pretrained LM을 확보해 fine-tunning한다거나...
LSTM은 이미 많은 sentence classification에서 안정적인 퍼포먼스를 내는, '교과서 단골모델'이다.
NLP를 뒤집어놓으셨던 BERT가 작년에 나온 후, BERT의 variant와 실제 적용 사례가 계속해서 나오고 있으며, BERT가 SOTA를 갈아치운 11개 Task는 그 NER과 같은 token-level 태스크부터 sentence-level, sequence-level까지 다양하다.
적어도 이 분야에 대해 공부하는 중이라면 이러한 사실을 모르는 사람은 없다. (개인적으로는 마치 어릴 때 포켓몬과 디지몬을 술술 외웠던 것처럼 모델들의 등장 배경이나 강점/약점은 꽤나 재밌는 부분이기 때문에)

(요즘 유명한 펀쿨섹좌식 화법을 따라하자면) 질문이 막연한 이유는 질문하는 사람이 막연한 상황에 있기 때문이다.
1. 데이터의 특성을 제대로 파악하지 못하고 있거나
2. 모델 아카이빙이 안되어있거나
Hugging Face와 같은 연구용 모델 환경이 잘 구축되면서 데이터 사이언티스트와 데이터 엔지니어의 구분이 많이 모호해졌지만, 굳이 구분하자면 1번이 데이터 사이언티스트, 2번이 데이터 엔지니어가 고민해야할 문제일 것 같다.
2의 경우는 비교적 해결이 쉽다. 데이터의 특성을 설명해주며 경험자에게 조언을 구하거나, SOTA 모델 관련 논문들을 읽으며 캐치업을 하면 된다. 다만, 한 때 SOTA였던 모델들이 굉장히 많은만큼 모든 모델을 테스트하지 않기 위해선 어느 정도의 경험이 필요하다.
반면, 1의 경우는 상대적으로 접근이 어렵다. 도메인 데이터의 패턴이 표준어와 많이 다른 경우, 예를 들면 현재 있는 제조업의 엔지니어링 로그의 경우, 해당 분야의 경험이 많지 않다면 특성을 파악하는데 시간이 꽤 걸릴 수 있다.
이를 해결하기 위해선 데이터를 오래 들여다보는 것도 필요하지만, 필연적으로 도메인전문가(현업)와의 협업이 필요하다. 
컨텍스트 이해부터 레이블링까지 자의적으로 접근하면, 모델 정합성은 높지만 데이터 정합성이 낮아 좋은 반응을 얻기 어렵게 된다. 예를 들면, 모델은 배운대로 잘 학습해서 정확도가 90%에 달하는데, 이를 본 실사용자가 '예측이 엉터리다', 혹은 '유용하지 않은 결과이다'고 피드백하는 경우다.
1에 대한 이해 후에는 기본적인 전처리 작업에 들어간다. 필요한 경우 시소러스(이음동의어 등의 처리를 위한)를 구축해야할 수 있다.

아래의 내용은 내가 새로운 태스크를 시작할 때, 모델 후보를 추려나가는 과정이다. (Trial&Error를 통해 계속 찾아나가는 과정 정도로 생각해주시면 될 것 같다.)
예를 들어, 태스크가 '특정 현상이 발생했을 때 이와 관련된 해결방안을 제시하는 것'이라고 한다.


1. 데이터의 단위를 확인한다.
	- 현상에 해당하는 데이터는 문장이며, 해결방안에 해당하는 데이터는 문장의 배열이다.
	- 현상은 겉으로 보기엔 문장 단위이지만, 실제론 그 안에 컨텍스트가 달라지는 여러 개의 절로 이루어져있다.
	-> 목표가 모델을 정하기 위해선 사용하게 될 데이터가 어떤 형태로 들어오는지, 어떤 형태로 변환할 수 있을지 확인해야 한다.
2. 태스크를 추상화 및 모델 탐색
	- 현상이 주어졌을 때 해결방안를 순차적으로 예측하는 모델이 있어야한다.
	- 문장 간의 NSP(Next Sentence Prediction) 태스크에 적합한 모델을 찾아야겠다.
	- NSP 태스크라면 우선 BERT family로 접근해봐야겠다.
	-> 1번과 더불어 주로 business 단위의 요청을 명세화하는 과정에 속한다. 이 과정에서 도메인 데이터 특성도 함께 고려해서 모델을 선정한다.
3. 모델에게 feeding할 input 단위를 확인해 전처리 방법을 정한다.
	- 해결방안이 문장 배열일 경우 2가지 방법이 있을 수 있다.
		- BERT에 입력하는 segment 단위를 2개로 하여, 뒷쪽 sentence에 문장 배열을 한번에 넣는다.
		- BERT 모델 초기 설정시 segment를 2보다 큰 수 k로 지정한다. (현상+해결방안 문장 수의 최대값)
	- 전처리는 mecab으로 tokenizing 후에 sentencepiece를 이용해 subword 단위로 나누어야 겠다.
	-> 1에서 정한 데이터의 단위와 일치할 수도 그렇지 않을 수도 있다. 예를 들어, WMD는 sentence 단위 태스크를 처리할 수 있지만, input은 token 단위에 가깝다. 이렇게 실제 모델 피딩 단위에 따라 전처리 방법도 다양해진다.

여기까지 완료하면, 그 이후엔 모델 구현(혹은 fork)해서 피팅할 차례다. 그러나, 논문에서 사용된 단어와 태스크를 사용해도 피팅이 쉽지 않은 경우도 많고, 잘 피팅이 되어도 막상 정성적인 결과가 적합하지 않을 수 있다.
태스크 수행을 위한 파이프라인에서 모델 설계 및 피팅은 일부분일 뿐이다. 그 앞단의 (수작업을 많이 하게 될 수 있는)전처리와 대상이 되는 후보군으로 예측 대상을 세분화하고, 모델에서 나온 결과에 대한 후처리까지 마무리까지가 한 사이클이다.
벌써 몇번째 반복되는 일이지만, 매번 새로운 태스크를 앞두고 모델을 선택해보려면 쉽지 않다. 자연어 처리 태스크를 수행하기 전 항상 고민되는 주제다.
<!--language-->